{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io \n",
    "import logging \n",
    "import PIL\n",
    "import hashlib\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from skimage.measure import label, regionprops\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('masks_csv', '', 'Path to the Mask CSV')\n",
    "flags.DEFINE_string('train_proportion', '0.8', 'Proportion of dataset dedicated for training')\n",
    "flags.DEFINE_string('image_directory', '', 'Input directory for raw images')\n",
    "flags.DEFINE_string('output_pir', '', 'Output directory for TFRecords')\n",
    "flags.DEFINE_string('label_map_path', '', 'Path to label map proto')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def main():\n",
    "    masks_csv = FLAGS.masks_csv\n",
    "    train_proportion = FLAGS.train_proportion\n",
    "    image_directory = FLAGS.image_directory\n",
    "    train_output_path = os.path.join(FLAGS.output_path, 'train.record')\n",
    "    val_output_path = os.path.join(FLAGS.output_path, 'validation.record')\n",
    "    label_map_dict = label_map_util.get_label_map_dict(FLAGS.label_map_path)\n",
    "\n",
    "    masks_dict = create_masks_dict(masks_csv)\n",
    "    image_ids = [key for key in masks_dict.keys()]\n",
    "    train_ids, val_ids = train_test_split(image_ids, train_size=float(train_proportion), \n",
    "                                          random_state=0)\n",
    "    train_masks_dict = {key: masks_dict[key] for key in train_ids}\n",
    "    val_masks_dict = {key: masks_dict[key] for key in val_ids}\n",
    "\n",
    "    create_tf_record(train_output_path, \n",
    "                     label_map_dict,\n",
    "                     image_directory,\n",
    "                     train_masks_dict) \n",
    "\n",
    "    create_tf_record(val_output_path, \n",
    "                     label_map_dict,\n",
    "                     image_directory,\n",
    "                     val_masks_dict)\n",
    "\n",
    "\n",
    "def create_tf_record(output_path, \n",
    "                     label_map_dict,\n",
    "                     image_directory, \n",
    "                     masks_dict):\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    for index, (image_id, masks) in enumerate(masks_dict.items()):\n",
    "        if index % 1000 == 0:\n",
    "            logging.info('On image {0} of {1}'.format(index, len(masks_dict)))\n",
    "\n",
    "        try:\n",
    "            class_names = ['ship'] * len(masks)\n",
    "            tf_example = create_tf_example(image_id, masks, class_names, label_map_dict, \n",
    "                image_directory)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "        except ValueError:\n",
    "            logging.error(\"Error while attempting to create a record for {}\".format(image_id))\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "\n",
    "\n",
    "def create_tf_example(file_name, \n",
    "                      masks,\n",
    "                      class_names, \n",
    "                      label_map_dict, \n",
    "                      image_directory,\n",
    "                      image_size=(768, 768)):\n",
    "\n",
    "    height = image_size[0]\n",
    "    width = image_size[1]\n",
    "    xmins = []\n",
    "    ymins = []\n",
    "    xmaxs = []\n",
    "    ymaxs = []\n",
    "    encoded_masks = []\n",
    "\n",
    "    # Read image\n",
    "    img_path = os.path.join(image_directory, file_name)\n",
    "    \n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    \n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    \n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    \n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    # Look up class id \n",
    "    class_ids = [label_map_dict[class_name] for class_name in class_names]\n",
    "\n",
    "    # Encode class names into bytes\n",
    "    class_names = [name.encode('utf8') for name in class_names]\n",
    "\n",
    "    # Encode mask into png and get bounding box coordinates  \n",
    "    for mask in masks:\n",
    "        mask_array = convert_mask_rle_to_img_array(mask)\n",
    "        encoded_mask = convert_img_array_to_png_str(mask_array)\n",
    "        encoded_masks.append(encoded_mask)\n",
    "        \n",
    "        try:\n",
    "            xmin, xmax, ymin, ymax = get_bbox_coordinates(mask_array)\n",
    "            xmins.append(xmin / width)\n",
    "            xmaxs.append(xmax / width)\n",
    "            ymins.append(ymin / height)\n",
    "            ymaxs.append(ymax / height)\n",
    "        except ValueError:\n",
    "            print(\"Error while attempting to create a record for {}\".format(file_name))\n",
    "\n",
    "    feature_dict = {\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(file_name.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(file_name.encode('utf8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(class_names),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(class_ids),\n",
    "        'image/object/mask': dataset_util.bytes_list_feature(encoded_masks),\n",
    "\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))    \n",
    "    \n",
    "    return example \n",
    "\n",
    "\n",
    "def create_masks_dict(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[df.EncodedPixels.notnull()]\n",
    "    masks_dict = {}\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        if row.ImageId not in masks_dict:\n",
    "            masks_dict[row.ImageId] = [row.EncodedPixels]\n",
    "        else:\n",
    "            masks_dict[row.ImageId].append(row.EncodedPixels)\n",
    "\n",
    "    return masks_dict\n",
    "\n",
    "\n",
    "\n",
    "def convert_mask_rle_to_img_array(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "def convert_img_array_to_png_str(img_array):\n",
    "    img = PIL.Image.fromarray(img_array)\n",
    "    output = io.BytesIO()\n",
    "    img.save(output, format='PNG')\n",
    "    \n",
    "    return output.getvalue()\n",
    "\n",
    "\n",
    "def get_bbox_coordinates(mask):\n",
    "    lbl = label(mask)\n",
    "    props = regionprops(lbl)\n",
    "\n",
    "    # Only keep masks that have bounding box area of greater than 1\n",
    "    props = [prop for prop in props if prop.bbox_area > 1]\n",
    "    if len(props) != 1:\n",
    "        raise ValueError(\"The mask had {} regions\".format(len(props)))\n",
    "    else:\n",
    "        prop = props[0]\n",
    "        xmin = prop.bbox[0]\n",
    "        xmax = prop.bbox[2]\n",
    "        ymin = prop.bbox[1]\n",
    "        ymax = prop.bbox[3]\n",
    "\n",
    "        return xmin, xmax, ymin, ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import mask, _mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.toBbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/wentao/Development/data/ships_detection'\n",
    "TRAIN_DIR = os.path.join(DATA_PATH, 'train')\n",
    "TEST_DIR = os.path.join(DATA_PATH, 'test')\n",
    "SAMPLE_CSV = os.path.join(DATA_PATH, 'sample_submission.csv')\n",
    "MASKS_CSV = os.path.join(DATA_PATH, 'train_ship_segmentations.csv')\n",
    "LABEL_MAP_PATH = '/home/wentao/Development/ml/models/research/object_detection/data/ship_detection.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_df = pd.read_csv(MASKS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = masks_df['EncodedPixels'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = map(int, T1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = list(T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= [['2', '3', '1', '1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= [[2, 3, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 1, 1]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-f1d58a7aa70d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/ml/models/research/pycocotools/_mask.pyx\u001b[0m in \u001b[0;36mpycocotools._mask.toBbox\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Development/ml/models/research/pycocotools/_mask.pyx\u001b[0m in \u001b[0;36mpycocotools._mask._frString\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "_mask.toBbox([[1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_binary_mask = np.array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   1,   1,   1,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   1,   1,   1,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   1,   1,   1,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   1,   1,   1,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    "                                  [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortran_detection_binary_mask = np.asfortranarray(detection_binary_mask)\n",
    "encoded_detection = mask.encode(fortran_detection_binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortran_detection_binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(detection_binary_mask))\n",
    "print(type(fortran_detection_binary_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': [9, 10], 'counts': b'^145000a0'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ndarray is not Fortran contiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-adf623a4ef73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_binary_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/ml/models/research/pycocotools/mask.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(bimask)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbimask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbimask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbimask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrleObjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/ml/models/research/pycocotools/_mask.pyx\u001b[0m in \u001b[0;36mpycocotools._mask.encode\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ndarray is not Fortran contiguous"
     ]
    }
   ],
   "source": [
    "mask.encode(detection_binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proportion=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wentao/anaconda3/envs/venv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "masks_dict = create_masks_dict(MASKS_CSV)\n",
    "image_ids = [key for key in masks_dict.keys()]\n",
    "train_ids, val_ids = train_test_split(image_ids, train_size=float(train_proportion), \n",
    "                                      random_state=0)\n",
    "train_masks_dict = {key: masks_dict[key] for key in train_ids}\n",
    "val_masks_dict = {key: masks_dict[key] for key in val_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(DATA_PATH, 'train.record')\n",
    "label_map_dict = label_map_util.get_label_map_dict(LABEL_MAP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_record(output_dir, label_map_dict, TRAIN_DIR, train_masks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while attempting to create a record for 492301277.jpg\n",
      "Error while attempting to create a record for 8432013c3.jpg\n",
      "Error while attempting to create a record for 8432013c3.jpg\n",
      "Error while attempting to create a record for 907193929.jpg\n",
      "Error while attempting to create a record for 64c84253b.jpg\n",
      "Error while attempting to create a record for 89e350a24.jpg\n",
      "Error while attempting to create a record for 7052088f4.jpg\n",
      "Error while attempting to create a record for 783ee2725.jpg\n",
      "Error while attempting to create a record for 16d28c367.jpg\n",
      "Error while attempting to create a record for feacf6719.jpg\n",
      "Error while attempting to create a record for feacf6719.jpg\n",
      "Error while attempting to create a record for 60ca4f877.jpg\n",
      "Error while attempting to create a record for 14a1efc07.jpg\n",
      "Error while attempting to create a record for 9b4eefbd7.jpg\n",
      "Error while attempting to create a record for 5a8785be5.jpg\n",
      "Error while attempting to create a record for 9a39363b0.jpg\n",
      "Error while attempting to create a record for 7ed8b9fdf.jpg\n",
      "Error while attempting to create a record for 7efdb69ff.jpg\n",
      "Error while attempting to create a record for 7efdb69ff.jpg\n",
      "Error while attempting to create a record for f98ba09af.jpg\n"
     ]
    }
   ],
   "source": [
    "val_output_dir = os.path.join(DATA_PATH, 'val.record')\n",
    "label_map_dict = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
    "create_tf_record(val_output_dir, label_map_dict, TRAIN_DIR, val_masks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_df = pd.read_csv(MASKS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_df[masks_df['ImageId'] == '1b117d4d5.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dict = create_masks_dict(MASKS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bbox_coordinates(mask):\n",
    "    lbl = label(mask)\n",
    "    props = regionprops(lbl)\n",
    "\n",
    "    # Only keep masks that have bounding box area of greater than 1\n",
    "    # props = [prop for prop in props if prop.bbox_area > 1]\n",
    "    if len(props) != 1:\n",
    "        import pdb; pdb.set_trace()\n",
    "        raise ValueError(\"The mask had {} regions\".format(len(props)))\n",
    "    else:\n",
    "        prop = props[0]\n",
    "        xmin = prop.bbox[0]\n",
    "        xmax = prop.bbox[2]\n",
    "        ymin = prop.bbox[1]\n",
    "        ymax = prop.bbox[3]\n",
    "\n",
    "        return xmin, xmax, ymin, ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in masks_dict['1b117d4d5.jpg']:\n",
    "    print(mask)\n",
    "    mask_array = convert_mask_rle_to_img_array(mask)\n",
    "    get_bbox_coordinates(mask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_array = convert_mask_rle_to_img_array('66124 2 66894 1 67662 1 68430 1 69198 1 69966 1 70734 1 73036 2 73804 2 74572 2')\n",
    "lbl = label(mask_array)\n",
    "props = regionprops(lbl)\n",
    "len(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in props:\n",
    "    print(prop.bbox_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in props:\n",
    "    print(prop.bbox[0], prop.bbox[2])\n",
    "    print(prop.bbox[1], prop.bbox[3])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "%matplotlib inline\n",
    "\n",
    "imshow(os.path.join(TRAIN_DIR, '1b117d4d5.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imshow(mask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = label(mask_array)\n",
    "props = regionprops(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(props[0].bbox[0])\n",
    "print(props[0].bbox[2])\n",
    "print(props[0].bbox[1])\n",
    "print(props[0].bbox[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(props[1].bbox[0])\n",
    "print(props[1].bbox[2])\n",
    "print(props[1].bbox[1])\n",
    "print(props[1].bbox[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props[1].bbox_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props[0].bbox_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ships_df = masks_df[masks_df['EncodedPixels'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ships_df.itertuples():\n",
    "    print(row.ImageId)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dict = {}\n",
    "for index, row in enumerate(ships_df.itertuples()):\n",
    "    if index % 10000 == 0:\n",
    "        print(\"Processed {} rows\".format(index))\n",
    "        \n",
    "    image_id = row.ImageId \n",
    "    encoded_pixels = row.EncodedPixels\n",
    "\n",
    "    if image_id not in masks_dict.keys():\n",
    "        masks_dict[image_id] = [encoded_pixels]\n",
    "    else:\n",
    "        masks_dict[image_id].append(encoded_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [key for key in masks_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masks_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masks_dict['00021ddc3.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['ship'.encode('utf8')] * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '00021ddc3.jpg'\n",
    "masks = masks_dict['00021ddc3.jpg']\n",
    "class_names = ['ship'] * 9\n",
    "label_map_dict = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
    "image_directory = TRAIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = create_tf_example(file_name, masks, class_names, label_map_dict, image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
